{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to deal with complex/large Documents"
      ],
      "metadata": {},
      "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b"
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Large documents are always a challenge for Search Engines.**\n",
        "\n",
        "One example of such complex files is Technical Specification Guides or Product Manuals, which can span **hundreds of pages and contain information in the form of images, tables, forms, and more. **Books are also complex due to their length and the presence of images or tables.\n",
        "\n",
        "These files are typically in PDF format. To better handle these PDFs, we need a smarter parsing method that treats each document as a special source and processes them page by page. The objective is to obtain more accurate and faster answers from our system. Fortunately, there are usually not many of these types of documents in an organization, allowing us to make exceptions and treat them differently.\n",
        "\n",
        "If **your use case is just PDFs,** for example, you can just use [PyPDF library](https://pypi.org/project/pypdf/) or [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0), **vectorize using OpenAI API and push the content to a vector-based index.** And this is problably the simplest and fastest way to go.  \n",
        "\n",
        "However if your use case entails **connecting to a datalake, or Sharepoint libraries or any other document data source with thousands of documents with multiple file types and that can change dynamically, then you would want to use the Ingestion and Document Cracking and AI-Enrichment capabilities of Azure Search engine, ** \n"
      ],
      "metadata": {},
      "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "from common.utils import parse_pdf, read_pdf_files, text_to_base64 # !!!!!\n",
        "\n",
        "from common.utils import (\n",
        "    get_search_results,\n",
        "    num_tokens_from_docs,\n",
        "    num_tokens_from_string\n",
        ")\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720138804887
        }
      },
      "id": "15f6044e-463f-4988-bc46-a3c3d641c15c"
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"data/imagehugefiles/\",exist_ok=True)\n",
        "    \n",
        "\n",
        "BLOB_CONTAINER_NAME = \"imagehugefiles\"\n",
        "BASE_CONTAINER_URL = \"https://blobstoragedjym6eiz2jhlk.blob.core.windows.net/\" + BLOB_CONTAINER_NAME + \"/\" \n",
        "# go to storage account->Settings-> Endpoints->Blob Service \n",
        "\n",
        "LOCAL_FOLDER = \"./data/imagehugefiles/\"\n",
        "\n",
        "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720138806889
        }
      },
      "id": "1598351d-a3ff-4811-a3d0-54290e964114"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Manual Document Cracking with Push to Vector-based Index"
      ],
      "metadata": {},
      "id": "bb87c647-158c-4f85-b569-5b9462f06c83"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within our demo storage account, we have a container named `books`, which holds 5 books of different lengths, languages, and complexities. Let's create a `cogsrch-index-books-vector` and load it with the pages of all these books.\n",
        "\n",
        "We begin by downloading these books to our local machine:"
      ],
      "metadata": {},
      "id": "75551868-1546-421b-a14e-e42618d88e61"
    },
    {
      "cell_type": "code",
      "source": [
        "books = [\"images.pdf\",\"azure-search.pdf\"] # upload these documents to the storage account"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1720138812824
        }
      },
      "id": "0999e24b-6a75-4fa1-9a5f-426cf0f0bdba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download the files to the local `./data/` folder:"
      ],
      "metadata": {},
      "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9"
    },
    {
      "cell_type": "code",
      "source": [
        "for book in tqdm(books):\n",
        "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
        "    print(book_url)\n",
        "    urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 2/2 [00:05<00:00,  2.77s/it]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://blobstoragedjym6eiz2jhlk.blob.core.windows.net/imagehugefiles/images.pdf?sp=r&st=2024-07-05T00:16:30Z&se=2024-07-31T08:16:30Z&spr=https&sv=2022-11-02&sr=c&sig=%2FZFyg3Y9Ug4FsaUoqS2wZDMUW9AarunZSnG07SIBLXQ%3D\nhttps://blobstoragedjym6eiz2jhlk.blob.core.windows.net/imagehugefiles/azure-search.pdf?sp=r&st=2024-07-05T00:16:30Z&se=2024-07-31T08:16:30Z&spr=https&sv=2022-11-02&sr=c&sig=%2FZFyg3Y9Ug4FsaUoqS2wZDMUW9AarunZSnG07SIBLXQ%3D\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1720138818841
        }
      },
      "id": "3554f0b7-fee8-4446-a155-5d22dc0f0888"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What to use: pyPDF or AI Documment Intelligence API (Form Recognizer)?\n",
        "\n",
        "In `utils.py` there is a **parse_pdf()** function. This utility function can parse local files using PyPDF library and can also parse local or from_url PDFs files using Azure AI Document Intelligence (Former Form Recognizer).\n",
        "\n",
        "If `form_recognizer=False`, the function will parse the PDF using the python pyPDF library, which 75% of the time does a good job.<br>\n",
        "\n",
        "Setting `form_recognizer=True`, is the best (and slower) parsing method using AI Documment Intelligence API (former known as Form Recognizer). You can specify the prebuilt model to use, the default is `model=\"prebuilt-document\"`. However, if you have a complex document with tables, charts and figures , you can try\n",
        "`model=\"prebuilt-layout\"`, and it will capture all of the nuances of each page (it takes longer of course).\n",
        "\n",
        "**Note: Many PDFs are scanned images. For example, any signed contract that was scanned and saved as PDF will NOT be parsed by pyPDF. Only AI Documment Intelligence API will work.**"
      ],
      "metadata": {},
      "id": "788cc0db-9dae-45f2-8943-2b6fa32fcc75"
    },
    {
      "cell_type": "code",
      "source": [
        "book_pages_map = dict()\n",
        "for book in books:\n",
        "    print(\"Extracting Text from\",book,\"...\")\n",
        "    \n",
        "    # Capture the start time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Parse the PDF\n",
        "    book_path = LOCAL_FOLDER+book\n",
        "    book_map = parse_pdf(file=book_path, form_recognizer=False, verbose=True)\n",
        "    book_pages_map[book]= book_map\n",
        "    \n",
        "    # Capture the end time and Calculate the elapsed time\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
        "    print(f\"{book} contained {len(book_map)} pages\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting Text from images.pdf ...\nExtracting text using PyPDF\nParsing took: 0.052433 seconds\nimages.pdf contained 2 pages\n\nExtracting Text from azure-search.pdf ...\nExtracting text using PyPDF\nParsing took: 40.272521 seconds\nazure-search.pdf contained 2094 pages\n\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1720138888938
        }
      },
      "id": "c1c63a2f-7a53-4346-8a1f-483cfd159d34"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check a random page of each book to make sure the parsing was done correctly:"
      ],
      "metadata": {},
      "id": "5de0a722-ae0c-4b57-802a-518f5d4d93fd"
    },
    {
      "cell_type": "code",
      "source": [
        "book_pages_map['images.pdf']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "[(0, 0, ' \\n \\n'), (1, 4, ' \\n \\n')]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720138890847
        }
      },
      "id": "0f53f81f-d1de-4c9c-ac22-d692ea04991b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this document only has images in it, we need a good PDF parser with good OCR capabilities in order to extract the content of this PDF. \n",
        "\n",
        "Let's try to parse this book again, but this time using Azure Document Intelligence API (former Form Recognizer)"
      ],
      "metadata": {},
      "id": "8bcdc1ee-71fc-49d2-8e7c-0964bc3a4370"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "book = \"images.pdf\" #YK\n",
        "book_path = LOCAL_FOLDER+book\n",
        "\n",
        "book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\",from_url=False, verbose=True)\n",
        "book_pages_map[book]= book_map"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting text using Azure Document Intelligence\nCPU times: user 140 ms, sys: 11.8 ms, total: 152 ms\nWall time: 9.54 s\n"
        }
      ],
      "execution_count": 7,
      "metadata": {},
      "id": "801c6bc2-467c-4418-aa7e-ef89a1e20e1c"
    },
    {
      "cell_type": "code",
      "source": [
        "book_pages_map['images.pdf']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "[(0,\n  0,\n  'WCS Data Landing Zone Subscription\\nAsk\\nSTITT\\nLydia\\nShared App Landing Zone Subscription\\nAsk STITT\\nLydia\\n= Microsoft Azure P Search resources, services, and docs (G+/)\\nWCL\\nData Landing Zone Subscription\\nWPB\\nData Landing Zone Subscription\\nAsk STITT\\nLydia\\nAsk\\nSTITT\\nLydia\\nWest US\\n<\\ntext-embedding-ada-002\\nPriority 1 AOAI\\nAPI Management Service\\n089\\nGPT-4 PTU\\nPriority 2 AOAI\\n< ! >\\nGPT-4 PAYGO\\nBilling/Logging Zone\\n2000)\\nSwitzerland North\\nPriority 3 AOAI\\nEvent Hubs\\nGPT-4 PTU or PAYGO\\ntext-embedding -ada-002\\nPower BI\\nStream Analytics Jobs\\nCopilot\\n2 :selected:\\nHome > Resource groups > ai-bootcamp > blobstoragejed5nzg3k2jp6\\nblobstoragejed5nzg3k2jp6 | Shared access signature\\nStorage account\\nO Search\\n« 8 Give feedback\\nFile shares\\nQueues\\nTables\\nSecurity + networking\\nNetworking\\nFront Door and CDN\\nAccess keys\\nShared access signature\\nQ Encryption\\nMicrosoft Defender for Cloud\\nData management :selected: Redundancy :selected: Data protection\\nObject replication\\nBlob inventory\\nStatic website\\nLearn more about creating an account SAS\\nAllowed services ® :selected: Blob :selected: File :selected: Queue :selected: Table\\nAllowed resource types @ :selected: Service :selected: Container :selected: Object\\nAllowed permissions C :selected: Read :selected: Write :selected: Delete :selected: List :selected: Add :selected: Create :selected: Update :selected: Process :selected: Immutable storage :selected: Perman€\\nBlob versioning permissions 0 :selected: Enables deletion of versions\\nAllowed blob index permissions 0 :selected: Read/Write :selected: Filter\\nStart and expiry date/time I :unselected:\\n<table><tr><td>Start</td><td>31/01/2024</td><td>:unselected:</td><td>8:55:41 PM</td></tr><tr><td>Enc</td><td>29/02/2024</td><td>:unselected:</td><td>4:55:41 AM</td></tr></table>\\n\\n\\n(UTC+00:00) Dublin, Edinburgh, Lisbon, London\\nAllowed IP addresses\\nFor example, 168.1.5.65 or 168.1.5.65-168.1.5.70 :unselected:   :unselected: '),\n (1,\n  1909,\n  'What\\'s Azure Al Search? Article · 11/22/2023\\nAzure Al Search (formerly known as \"Azure Cognitive Search\") provides secure information retrieval at scale over user-owned content in traditional and conversational search applications.\\nInformation retrieval is foundational to any app that surfaces text and vectors. Common scenarios include catalog or document search, data exploration, and increasingly chat- style search modalities over proprietary grounding data. When you create a search service, you\\'ll work with the following capabilities:\\n· A search engine for full text and vector search over a search index\\n· Rich indexing, with integrated data chunking and vectorization (preview), lexical analysis for text, and optional Al enrichment for content extraction and transformation\\n· Rich query syntax for vector queries, text search, hybrid search, fuzzy search, autocomplete, geo-search and others\\n· Azure scale, security, and reach\\n· Azure integration at the data layer, machine learning layer, Azure Al services and Azure OpenAl\\nCreate a search service\\nArchitecturally, a search service sits between the external data stores that contain your un-indexed data, and your client app that sends query requests to a search index and handles the response.\\n<table><tr><th>Your content</th><th>Full indexing</th><th colSpan=3>9870\\nAzure Al Search</th><th>Query requests</th></tr><tr><td></td><td>Refresh indexing</td><td>Indexing</td><td rowSpan=2>Indexes and other structures</td><td>Query</td><td></td></tr><tr><td>(in the cloud or behind a firewall)</td><td>Al enrichment</td><td>engine</td><td>engine</td><td>Query responses</td></tr></table>\\n\\n\\n\\n\\n\\n\\n\\n\\nYour app 1. Collects user input\\n2. Formulates and sends requests\\n3. Handles responses a result set a single document ')]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720138913934
        }
      },
      "id": "2b1229d1-f38f-412f-b313-9d5ac1ab6aad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As demonstrated above, Azure Document Intelligence proves to be superior to pyPDF. \n",
        "\n",
        "**For production scenarios, we strongly recommend using Azure Document Intelligence consistently**. When doing so, it's important to make a wise choice between the available models, such as \"prebuilt-document,\" \"prebuilt-layout,\" or others. You can find more information on model selection [HERE](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/choose-model-feature?view=doc-intel-3.0.0).\n"
      ],
      "metadata": {},
      "id": "9c279dfb-4fed-41b8-89e1-0ca2cefbcdc9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}